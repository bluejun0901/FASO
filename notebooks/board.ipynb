{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3a3907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ROOT = Path(os.getenv(\"PROJECT_ROOT\")).resolve() # type: ignore\n",
    "MODEL_ROOT = Path(os.getenv(\"MODEL_ROOT\")).resolve() # type: ignore\n",
    "DATA_ROOT = Path(os.getenv(\"DATA_ROOT\")).resolve() # type: ignore\n",
    "CONFIG_ROOT = Path(os.getenv(\"CONFIG_ROOT\")).resolve() # type: ignore\n",
    "SRC_ROOT = Path(os.getenv(\"SRC_ROOT\")).resolve() # type: ignore\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "sys.path.append(str(SRC_ROOT / 'prepare_data'))\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from datasets import Dataset\n",
    "import json\n",
    "from utils.utility import *\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce23396",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(CONFIG_ROOT / input(\"input configuration path: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836ba837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading generated ouputs from /src/gs25009/LLM_DAG_ALLIGN/dataset/preprocessed/final_generated.json...\n",
      "Loaded successfully\n"
     ]
    }
   ],
   "source": [
    "gen_filename = input(\"input generation filename: \")\n",
    "gen_output_path = DATA_ROOT / config.dataset_output_dir / gen_filename\n",
    "print(f\"Loading generated ouputs from {str(gen_output_path)}...\")\n",
    "with open(gen_output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "dataset = Dataset.from_dict(dataset)\n",
    "print(\"Loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb14739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import regex as re\n",
    "\n",
    "pattern = r\"Preferred:\\s*[\\\"']?([12])[\\\"']?\"\n",
    "\n",
    "def generate_comparisons(dataset: Dataset) -> list[dict]:\n",
    "    pairs = []\n",
    "    for k, example in enumerate(dataset):\n",
    "        prompt = example['prompt'] # type: ignore\n",
    "        ref = \"\"\n",
    "        summaries = example['summaries'] # type: ignore\n",
    "        \n",
    "        for i, y1 in enumerate(summaries):\n",
    "            for j, y2 in enumerate(summaries):\n",
    "                if i < j:\n",
    "                    pairs.append({\n",
    "                        'prompt': prompt,\n",
    "                        'y1': y1,\n",
    "                        'y2': y2,\n",
    "                        'ref': ref,\n",
    "                        'meta': f\"{k}, {i}, {j}\"\n",
    "                    })\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "pairs = generate_comparisons(dataset)\n",
    "\n",
    "def _parse_output_line(line: str) -> tuple[int, int | None]:\n",
    "    obj = json.loads(line)\n",
    "    idx = int(obj.get(\"custom_id\"))  # came from compare_batch_0\n",
    "    body = obj.get(\"response\", {}).get(\"body\", {})\n",
    "    output = body.get(\"output\", [])[1].get(\"content\", \"\")[0]\n",
    "    if not output:\n",
    "        return idx, None\n",
    "    output_text = output.get(\"text\", \"\")\n",
    "    match = re.search(pattern, output_text)\n",
    "    if not match:\n",
    "        return idx, None\n",
    "    # Map '1' -> 0 (y1), '2' -> 1 (y2)\n",
    "    return idx, (0 if match.group(1) == \"1\" else 1)\n",
    "\n",
    "def compare_batch_2() -> list[int | None]:\n",
    "    result: list[int | None] = [None for _ in range(len(pairs))]\n",
    "\n",
    "    b = batch\n",
    "\n",
    "    if getattr(b, \"status\", None) == \"completed\" and getattr(b, \"output_file_id\", None):\n",
    "        content_resp = client.files.content(str(b.output_file_id))\n",
    "        # Support both text attribute and binary stream\n",
    "        data = getattr(content_resp, \"text\", None)\n",
    "        if data is None:\n",
    "            # Assume file-like stream with .read()\n",
    "            raw = content_resp.read()\n",
    "            if isinstance(raw, bytes):\n",
    "                data = raw.decode(\"utf-8\", errors=\"ignore\")\n",
    "            else:\n",
    "                data = str(raw)\n",
    "        for raw_line in data.splitlines():\n",
    "            if not raw_line.strip():\n",
    "                continue\n",
    "            idx, pref = _parse_output_line(raw_line)\n",
    "            if 0 <= idx < len(result):\n",
    "                result[idx] = pref\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e087e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preference_builders import CachedPreferenceScorer\n",
    "a = CachedPreferenceScorer(str(DATA_ROOT / \"preprocessed\" / \"final_comparisons.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9c508c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "for i in range(10):\n",
    "    g = [[] for _ in range(10)]\n",
    "    for j in range(10):\n",
    "        for k in range(10):\n",
    "            if j >= k: \n",
    "                continue\n",
    "            comp = a.compare(\"\", \"\", \"\", \"\", f\"{i}, {j}, {k}\")\n",
    "            if comp:\n",
    "                g[k].append(j)\n",
    "            else:\n",
    "                g[j].append(k)\n",
    "    b.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_cycle(adj):\n",
    "    \"\"\"\n",
    "    adj: 리스트 기반 인접리스트. adj[u] = u에서 나가는 간선의 목적지 리스트\n",
    "    사이클 있으면 True, 없으면 False\n",
    "    \"\"\"\n",
    "    n = len(adj)\n",
    "    WHITE, GRAY, BLACK = 0, 1, 2\n",
    "    color = [WHITE] * n\n",
    "\n",
    "    def dfs(u):\n",
    "        color[u] = GRAY\n",
    "        for v in adj[u]:\n",
    "            if color[v] == GRAY:   # 백엣지 → 사이클\n",
    "                return True\n",
    "            if color[v] == WHITE and dfs(v):\n",
    "                return True\n",
    "        color[u] = BLACK\n",
    "        return False\n",
    "\n",
    "    for u in range(n):\n",
    "        if color[u] == WHITE and dfs(u):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_cycle(adj):\n",
    "    \"\"\"\n",
    "    adj: 인접 리스트 (리스트 기반), adj[u] = u -> v 간선 리스트\n",
    "    사이클 있으면 그 경로(list)를 반환, 없으면 None 반환\n",
    "    \"\"\"\n",
    "    n = len(adj)\n",
    "    WHITE, GRAY, BLACK = 0, 1, 2\n",
    "    color = [WHITE] * n\n",
    "    parent = [-1] * n\n",
    "    cycle = []\n",
    "\n",
    "    def dfs(u):\n",
    "        nonlocal cycle\n",
    "        color[u] = GRAY\n",
    "        for v in adj[u]:\n",
    "            if color[v] == WHITE:\n",
    "                parent[v] = u\n",
    "                if dfs(v):\n",
    "                    return True\n",
    "            elif color[v] == GRAY:  # 사이클 발견\n",
    "                # v → ... → u → v 사이클 복원\n",
    "                cycle = [v]\n",
    "                x = u\n",
    "                while x != v:\n",
    "                    cycle.append(x)\n",
    "                    x = parent[x]\n",
    "                cycle.append(v)\n",
    "                cycle.reverse()\n",
    "                return True\n",
    "        color[u] = BLACK\n",
    "        return False\n",
    "\n",
    "    for u in range(n):\n",
    "        if color[u] == WHITE and dfs(u):\n",
    "            return cycle\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554343c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "for i, adj in enumerate(b):\n",
    "    dot = Digraph()\n",
    "\n",
    "    for u, nbrs in enumerate(adj):\n",
    "        for v in nbrs:\n",
    "            dot.edge(str(u), str(v))\n",
    "\n",
    "    dot.render(f\"graph{i}\", format=\"png\", view=False)  # graph.png 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec91118",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(DATA_ROOT / \"kk.jsonl\")) as f:\n",
    "    text = f.read()\n",
    "a = text.split('\"output_tokens\": ')\n",
    "sum = 0\n",
    "for i, line in enumerate(a):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if i < 10:\n",
    "        print(line.split(\",\")[0])\n",
    "    sum += int(line.split(\",\")[0])\n",
    "\n",
    "print(sum / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e29f7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018404\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "with open(str(DATA_ROOT / \"preprocessed\" / \"request_pairwise_openai_2025-09-02_21-16-06\" / \"223_2025-09-02_21-16-17.jsonl\")) as f:\n",
    "    tokens = encoding.encode(f.read())\n",
    "print(len(tokens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_dag_allign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
