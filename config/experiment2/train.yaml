name: acyclic_reason_kahn

model_name: sft/checkpoint-80

dataset_output_dir: experiment2/preprocessed
model_output_dir: experiment2
log_dir: experiment2

trainer:
  type: dpo
  dpo:
    logging_steps: 20
    per_device_train_batch_size: 2
    gradient_accumulation_steps: 8
    fp16: True
    num_train_epochs: 1.0
    save_steps: 1000
    save_total_limit: 0
    learning_rate: 6.25e-07
    weight_decay: 0.1
    lr_scheduler_type: cosine
    warmup_steps: 1500
    warmup_ratio: 0.03